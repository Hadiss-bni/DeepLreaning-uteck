{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework-series1-N6-Thresholdcallback.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzRPMHQW5w4z85nGpH/ww6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hadiss-bni/DeepLreaning-UtechAcademy/blob/master/Homework_series1_N6_Thresholdcallback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UQif49TOOHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "058af47e-5a61-4a84-97ab-398646bec242"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
        "!mkdir dataset\n",
        "!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-18 16:18:27--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 929 [text/plain]\n",
            "Saving to: ‘dataset.py.2’\n",
            "\n",
            "\rdataset.py.2          0%[                    ]       0  --.-KB/s               \rdataset.py.2        100%[===================>]     929  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-18 16:18:27 (51.1 MB/s) - ‘dataset.py.2’ saved [929/929]\n",
            "\n",
            "mkdir: cannot create directory ‘dataset’: File exists\n",
            "--2020-09-18 16:18:27--  https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat [following]\n",
            "--2020-09-18 16:18:27--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3989009 (3.8M) [application/octet-stream]\n",
            "Saving to: ‘dataset/Data_hoda_full.mat.2’\n",
            "\n",
            "Data_hoda_full.mat. 100%[===================>]   3.80M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-18 16:18:28 (34.2 MB/s) - ‘dataset/Data_hoda_full.mat.2’ saved [3989009/3989009]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZP2R8hsSibd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0cdfcaf5-ef45-49e7-fe5b-33e479ed4019"
      },
      "source": [
        "# 1. Import libraries and module\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.callbacks import Callback\n",
        "import numpy as np\n",
        "from dataset import load_hoda\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(123)  # for reproducibility\n",
        "\n",
        "# Load pre-shuffled HODA data into train and test sets\n",
        "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n",
        "                                                                        training_sample_size=3500,\n",
        "                                                                        test_sample_size=400,size=28)\n",
        "\n",
        "# Preprocess input data\n",
        "''' 3.1: input data in numpy array format'''\n",
        "x_train = np.array(x_train_original)\n",
        "x_test = np.array(x_test_original)\n",
        "'''3.2 normalize our data values to the range [0, 1]'''\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n",
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)\n",
        "\n",
        "\n",
        "# 4. Preprocess class labels\n",
        "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n",
        "\n",
        "\n",
        "# test and validation set\n",
        "x_val = x_test[:200]\n",
        "x_test = x_test[200:]\n",
        "y_val = y_test[:200]\n",
        "y_test = y_test[200:]\n",
        "\n",
        "# 5. Define model architecture\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# 6. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#callback for stop training the model when  acc=0.75\n",
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        accuracy = logs[\"accuracy\"]\n",
        "        if accuracy >= self.threshold:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callback = MyThresholdCallback(threshold=0.75)\n",
        "\n",
        "\n",
        "\n",
        "# 7. Fit model on training data\n",
        "history = model.fit(x_train, y_train,\n",
        "          epochs=200, batch_size=256, validation_data = (x_val, y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 2.0772 - accuracy: 0.3011 - val_loss: 1.4139 - val_accuracy: 0.7550\n",
            "Epoch 2/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1.2374 - accuracy: 0.5866 - val_loss: 0.5698 - val_accuracy: 0.8500\n",
            "Epoch 3/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7929 - accuracy: 0.7231 - val_loss: 0.4058 - val_accuracy: 0.8950\n",
            "Epoch 4/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.5973 - accuracy: 0.8009 - val_loss: 0.3056 - val_accuracy: 0.9050\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}